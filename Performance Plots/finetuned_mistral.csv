loss,grad_norm,learning_rate,epoch,step,train_runtime,train_samples_per_second,train_steps_per_second,total_flos,train_loss
1.2954,0.7031790018081665,0.00018367346938775512,0.03,25,,,,,
1.0534,0.5870575904846191,0.00016326530612244898,0.06,50,,,,,
1.0455,0.605229914188385,0.00014285714285714287,0.09,75,,,,,
1.0076,0.5714181661605835,0.00012244897959183676,0.11,100,,,,,
1.0203,0.5080958604812622,0.00010204081632653062,0.14,125,,,,,
1.0025,0.5784084796905518,8.163265306122449e-05,0.17,150,,,,,
1.0113,0.4789358079433441,6.122448979591838e-05,0.2,175,,,,,
0.9938,0.6284953355789185,4.0816326530612245e-05,0.23,200,,,,,
1.0172,0.49969980120658875,2.0408163265306123e-05,0.26,225,,,,,
1.0102,0.5275124907493591,0.0,0.29,250,,,,,
,,,0.29,250,1675.5228,1.194,0.149,1.9488239998058496e+16,1.045726173400879
