loss,grad_norm,learning_rate,epoch,step,train_runtime,train_samples_per_second,train_steps_per_second,total_flos,train_loss
1.3536,0.9421519637107849,0.00018367346938775512,0.03,25,,,,,
1.1156,inf,0.00016571428571428575,0.06,50,,,,,
1.1285,0.7835822701454163,0.0001453061224489796,0.09,75,,,,,
1.0965,0.7796308994293213,0.0001248979591836735,0.11,100,,,,,
1.0892,0.7948692440986633,0.00010448979591836735,0.14,125,,,,,
1.0887,0.8703497648239136,8.408163265306123e-05,0.17,150,,,,,
1.086,0.7060002088546753,6.36734693877551e-05,0.2,175,,,,,
1.0714,0.7546376585960388,4.3265306122448984e-05,0.23,200,,,,,
1.0975,0.6499924659729004,2.2857142857142858e-05,0.26,225,,,,,
1.0775,0.7006698846817017,2.4489795918367347e-06,0.29,250,,,,,
,,,0.29,250,1850.3334,1.081,0.135,2.1975885566976e+16,1.1204660110473632
